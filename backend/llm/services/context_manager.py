# backend/llm/services/context_manager.py

from backend.llm.memory.context_builder import build_context
from backend.utils.source_loader import load_text_from_local_sources

async def build_llm_context(model_id, system_prompt, user_messages, memory_settings):
    return await build_context(
        model_id=model_id,
        system_prompt=system_prompt,
        user_messages=user_messages,
        memory_settings=memory_settings
    )

def append_local_sources(context: list[dict], source_ids: list[int]) -> None:
    if not source_ids:
        return

    texts = load_text_from_local_sources(source_ids)

    print(f"[ğŸ“ ë¡œì»¬ ì†ŒìŠ¤ ID ëª©ë¡]: {source_ids}")
    print(f"[ğŸ“ ë¡œì»¬ ì†ŒìŠ¤ ì°¸ê³  ë¬¸ì„œ ìˆ˜]: {len(texts)}ê°œ")

    for idx, text in enumerate(texts):
        header = text.split('\\n')[0] if '\\n' in text else text[:50]
        print(f"[ğŸ“„ ë¬¸ì„œ {idx+1}] í—¤ë”: {header}")

    for text in texts:
        role_intro = "This is character information:" if " is a " in text else "This is background knowledge:"
        context.append({
            "role": "system",
            "content": f"{role_intro}\\n{text[:500]}"
        })
